{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import requirements files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import PIL.Image\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import shutil\n",
    "import zipfile\n",
    "from glob import glob\n",
    "from typing import List, Tuple\n",
    "\n",
    "import click\n",
    "import h5py\n",
    "import numpy as np\n",
    "from scipy.io import loadmat\n",
    "from scipy.ndimage import gaussian_filter\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from utils import avg_box, gaussian_filter_density\n",
    "import math\n",
    "import torch\n",
    "import scipy.io as sio\n",
    "\n",
    "# Increase the aximum numbers of pixels in order for PIL to be able to open large images\n",
    "PIL.Image.MAX_IMAGE_PIXELS = 1262080000 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hn7QIEm6rhzb"
   },
   "source": [
    "# Cropping Yosemite dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EfU80poFrkd5"
   },
   "source": [
    "**Create annotation for Yosemite dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xyjdvD7CrqXC"
   },
   "outputs": [],
   "source": [
    "file_path = \"datasets/yosemite/labels.txt\"  \n",
    "im = Image.open('datasets/yosemite/z20_label.png') \n",
    "pix = im.load()\n",
    "x, y = im.size\n",
    "with open(file_path, \"w\") as f:\n",
    "  for i in range(x):\n",
    "    for j in range(y):\n",
    "      value = pix[i, j]\n",
    "      if value > 0:\n",
    "        rel_x = i\n",
    "        rel_y = j\n",
    "        f.write(f\"{rel_x} {rel_y}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Xmzqh9dltGv2"
   },
   "source": [
    "## Crop function from full image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1RboNxQctLs1"
   },
   "outputs": [],
   "source": [
    "def smallCrop(image, cw, ch, labels, left, top):\n",
    "    \"\"\"\n",
    "    Crop a specific region from an image and adjust the coordinates of labels\n",
    "    within that cropped region.\n",
    "\n",
    "    Note:\n",
    "    The function assumes that the provided crop width (cw) and height (ch) \n",
    "    do not exceed the dimensions of the image. It raises an error if the crop size \n",
    "    is invalid.\n",
    "\n",
    "    Args:\n",
    "        image: The image to crop, typically a PIL Image object.\n",
    "        cw: The width of the crop area.\n",
    "        ch: The height of the crop area.\n",
    "        labels: A list of tuples containing the (x, y) coordinates of the labels.\n",
    "        left: The x-coordinate of the top-left corner of the crop area.\n",
    "        top: The y-coordinate of the top-left corner of the crop area.\n",
    "\n",
    "    Returns:\n",
    "        A tuple consisting of:\n",
    "            cropped_image: The cropped portion of the image.\n",
    "            updated_labels: A list of updated label coordinates relative to the cropped area.\n",
    "    \"\"\"\n",
    "    \n",
    "    width, height = image.size\n",
    "    if cw >= min(width, height):\n",
    "        raise ValueError(\"Crop size exceeds image dimensions\")\n",
    "\n",
    "    # 27200 x 46400 pixels in image\n",
    "    # zone 19200 x 38400\n",
    "    while True:\n",
    "        #Define the zone to crop\n",
    "        right = left + cw\n",
    "        bottom = top + ch\n",
    "        cropped_image = image.crop((left, top, right, bottom))\n",
    "\n",
    "        updated_labels = []\n",
    "        for x, y in labels:\n",
    "            # Condition to check if the label is inside the cropped area\n",
    "            # '=' is used to include the border of the cropped area\n",
    "            if left <= x <= right and top <= y  <= bottom:\n",
    "                # Label is inside the cropped area, update its coordinates\n",
    "                updated_x = (x - left)\n",
    "                updated_y = (y - top)\n",
    "                updated_labels.append((updated_x, updated_y))\n",
    "\n",
    "        return cropped_image, updated_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WtnRCZAgtdYg"
   },
   "outputs": [],
   "source": [
    "def main_row(input_image_path, input_label_path, output_folder, cw, ch):\n",
    "  \n",
    "    \"\"\"\n",
    "    Process an input image by cropping it into smaller regions and saving \n",
    "    both the cropped images and their associated labels to specified output folders.\n",
    "\n",
    "    This function divides the image into four zones (A, B, C, D), and for each zone,\n",
    "    crops the image into smaller sub-images based on the given crop width (cw) and crop height (ch). \n",
    "    It then saves the cropped images and their corresponding labels into the appropriate directories.\n",
    "\n",
    "    Note:\n",
    "    - The image is split into 4 predefined zones (A, B, C, D).\n",
    "    - The function assumes labels are given as (x, y) coordinates, one per line in a text file.\n",
    "    - The image and label files are saved in separate subfolders within each zone folder.\n",
    "\n",
    "    Args:\n",
    "        input_image_path: Path to the input image file.\n",
    "        input_label_path: Path to the input label file, where each label is represented as \"x y\".\n",
    "        output_folder: The parent directory where the cropped images and labels will be saved.\n",
    "        cw: The width of the crop area (in pixels).\n",
    "        ch: The height of the crop area (in pixels).\n",
    "\n",
    "    Returns:\n",
    "        None: The function does not return any values but saves the cropped images and labels in the specified output folder.\n",
    "    \"\"\"\n",
    "  \n",
    "    # Create output folders if they don't exist\n",
    "    os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "    # Yosemite has 4 zones\n",
    "    folders = ['zone_A', 'zone_B', 'zone_C', 'zone_D']\n",
    "\n",
    "    # Create subfolders for images and labels\n",
    "    for folder in folders:\n",
    "      zone = os.path.join(output_folder, folder)\n",
    "      os.makedirs(os.path.join(zone, 'images'), exist_ok=True)\n",
    "      os.makedirs(os.path.join(zone, 'labels'), exist_ok=True)\n",
    "\n",
    "    # Load the input image\n",
    "    image = Image.open(input_image_path)\n",
    "\n",
    "    # Load labels from a txt file (assuming one label per line in the format \"x y\")\n",
    "    with open(input_label_path, 'r') as label_file:\n",
    "        labels = [tuple(map(float, line.strip().split())) for line in label_file]\n",
    "\n",
    "    # Define limits for the zones to crop\n",
    "    x_min = 4000\n",
    "    x_max = x_min + int(19200/4) - cw\n",
    "    y_min = 4000\n",
    "    y_max = y_min + 38400\n",
    "    count = 0\n",
    "\n",
    "    # Loop through the zones\n",
    "    for i in range(len(folders)):\n",
    "      print(f\"Width range {x_min} - {x_max}\")\n",
    "      print(f\"Height range {y_min} - {y_max}\")\n",
    "      j = 1\n",
    "\n",
    "      # Loop through the crops\n",
    "      for top in range(y_min, y_max, ch):\n",
    "        for left in range(x_min, x_max, cw):\n",
    "          print(count, end = \" \")\n",
    "          print(\"Left:\", left, \"Top:\", top)\n",
    "          # Crop the image based on the coordinates\n",
    "          cropped_image, updated_labels = smallCrop(image, cw, ch, labels, left, top)\n",
    "\n",
    "          # Save the cropped image\n",
    "          output_image_path = os.path.join(output_folder, folders[i], 'images', f'IMG_{count}.jpg')\n",
    "          cropped_image.save(output_image_path)\n",
    "\n",
    "          # Save the updated labels to a new txt file\n",
    "          output_label_path = os.path.join(output_folder, folders[i], 'labels', f'IMG_{count}.txt')\n",
    "          with open(output_label_path, 'w') as updated_label_file:\n",
    "              for x, y in updated_labels:\n",
    "                  updated_label_file.write(f\"{x} {y}\\n\")\n",
    "          j += 1\n",
    "          count += 1\n",
    "      print(f\"The number of images and labels in {folders[i]}: {j-1}\\n\")\n",
    "      # Increase the x_min and x_max for the next zone\n",
    "      x_min += int(19200/4)\n",
    "      x_max += int(19200/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "H5CZ6o0MthHk"
   },
   "outputs": [],
   "source": [
    "#Row by Row cropping\n",
    "input_image_path = 'datasets/yosemite/z20_data.png'  # Specify the path to your input image\n",
    "input_label_path = 'datasets/yosemite/labels.txt'  # Specify the path to your input labels file\n",
    "crop_size =  1536 # Specify the size of the square crop (both width and height)\n",
    "output_folder = f'datasets/yosemite_1536_no_crop'  # Specify the output folder where cropped images and labels will be saved\n",
    "\n",
    "main_row(input_image_path, input_label_path, output_folder, crop_size, crop_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MDw54ybouo3M"
   },
   "outputs": [],
   "source": [
    "def plot_cropped_images_with_labels(folder):\n",
    "    \"\"\"\n",
    "    Display cropped images from a specified folder along with their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        folder: The path to the folder containing the subfolders 'images' and 'labels'.\n",
    "                Each subfolder should contain the cropped image files and label files.\n",
    "\n",
    "    Returns:\n",
    "        None: The function does not return any values. Instead, it displays the cropped image \n",
    "              with overlaid labels using `matplotlib`.\n",
    "    \"\"\"\n",
    "    \n",
    "    image_folder = os.path.join(folder,'images')\n",
    "    label_folder = os.path.join(folder,'labels')\n",
    "    # List image and label files in the respective folders\n",
    "    image_files = os.listdir(image_folder)\n",
    "    label_files = os.listdir(label_folder)\n",
    "\n",
    "    for image_filename in image_files:\n",
    "        # Check if a corresponding label file exists\n",
    "        label_filename = os.path.splitext(image_filename)[0] + '.txt'\n",
    "        if label_filename not in label_files:\n",
    "            continue\n",
    "\n",
    "        image_path = os.path.join(image_folder, image_filename)\n",
    "        label_path = os.path.join(label_folder, label_filename)\n",
    "\n",
    "        # Load the cropped image\n",
    "        cropped_image = Image.open(image_path)\n",
    "\n",
    "        # Load labels from the provided label file\n",
    "        with open(label_path, 'r') as label_file:\n",
    "            labels = [tuple(map(float, line.strip().split())) for line in label_file]\n",
    "\n",
    "        plt.figure(figsize=(6, 6))\n",
    "        plt.imshow(cropped_image)\n",
    "        plt.title(image_filename)\n",
    "\n",
    "        for x, y in labels:\n",
    "            plt.plot(x, y, 'ro', markersize=2)  # Plot labels as red points\n",
    "\n",
    "        plt.axis('off')\n",
    "        plt.show()\n",
    "\n",
    "# Specify the path to the target folder containing cropped images and labels\n",
    "# example: datasets/yosemite_1536/zone_A\n",
    "folder = 'Path/to/your/target/folder'  \n",
    "plot_cropped_images_with_labels(folder)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Crop function from image of size 1536x1536"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from PIL import Image\n",
    "\n",
    "def split_9_images_labels(source_img, source_label, output, zone, num_width, num_height):\n",
    "    \"\"\"\n",
    "    Split images and their corresponding labels into smaller segments.\n",
    "\n",
    "    This function takes an image and its corresponding label file and splits them into smaller segments (grid).\n",
    "    The function divides the image into a grid of size `num_width` x `num_height`, cropping the image into\n",
    "    smaller regions and updating the label coordinates based on the respective segment.\n",
    "\n",
    "    The smaller segments are saved as new image and label files in the output folder. A separate folder for\n",
    "    each zone is created in the output directory to store the cropped images and updated labels.\n",
    "\n",
    "    Args:\n",
    "        source_img (str): The path to the source folder containing the original images.\n",
    "        source_label (str): The path to the source folder containing the corresponding label files.\n",
    "        output (str): The path to the output folder where cropped images and labels will be saved.\n",
    "        zone (str): The subfolder name (zone) where the cropped images and labels will be stored.\n",
    "        num_width (int): The number of segments to divide the image into along the width.\n",
    "        num_height (int): The number of segments to divide the image into along the height.\n",
    "    \"\"\"\n",
    "    # Make folders if they don't exist\n",
    "    os.makedirs(os.path.join(output, zone, 'images'), exist_ok=True)\n",
    "    os.makedirs(os.path.join(output, zone, 'labels'), exist_ok=True)\n",
    "\n",
    "    # Get list of images in the source folder\n",
    "    image_files = [f for f in os.listdir(source_img) if f.endswith((\".jpg\", \".jpeg\", \".png\"))]\n",
    "\n",
    "    for image_filename in image_files:\n",
    "        # Get label file corresponding to the image\n",
    "        label_filename = os.path.splitext(image_filename)[0] + '.txt'\n",
    "        label_path = os.path.join(source_label, label_filename)\n",
    "\n",
    "        # Check if the corresponding label file exists\n",
    "        if not os.path.exists(label_path):\n",
    "            print(f\"Warning: Label file not found for image '{image_filename}'\")\n",
    "            continue\n",
    "\n",
    "        # Load labels from the label file\n",
    "        with open(label_path, 'r') as label_file:\n",
    "            labels = [tuple(map(float, line.strip().split())) for line in label_file]\n",
    "\n",
    "        # Open the image\n",
    "        image_path = os.path.join(source_img, image_filename)\n",
    "        image = Image.open(image_path)\n",
    "        width, height = image.size\n",
    "        \n",
    "        # Calculate the size of each smaller segment\n",
    "        segment_height = height // num_height\n",
    "        segment_width = width // num_width\n",
    "\n",
    "        # Loop through the grid\n",
    "        for i in range(num_height):\n",
    "            for j in range(num_width):\n",
    "                # Define the coordinates of the segment\n",
    "                left = j * segment_width\n",
    "                right = (j + 1) * segment_width\n",
    "                top = i * segment_height\n",
    "                bottom = (i + 1) * segment_height\n",
    "\n",
    "                # Crop the image\n",
    "                cropped_image = image.crop((left, top, right, bottom))\n",
    "                \n",
    "                # Save the cropped image\n",
    "                output_image_path = os.path.join(output, zone, 'images', f'{os.path.splitext(image_filename)[0]}_section_{i*num_width+j}.jpg')\n",
    "                cropped_image.save(output_image_path)\n",
    "\n",
    "                # Update labels\n",
    "                update_labels = []\n",
    "                for x, y in labels:\n",
    "                    if left <= x <= right and top <= y <= bottom:\n",
    "                        update_x = x - left\n",
    "                        update_y = y - top\n",
    "                        update_labels.append((update_x, update_y))\n",
    "\n",
    "                # Save the updated labels\n",
    "                output_label_path = os.path.join(output, zone, 'labels', f'{os.path.splitext(image_filename)[0]}_section_{i*num_width+j}.txt')\n",
    "                with open(output_label_path, 'w') as update_label_file:\n",
    "                    for x, y in update_labels:\n",
    "                        update_label_file.write(f\"{x} {y}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_source = 'datasets/yosemite_1536_no_crop/zone_A/images'\n",
    "label_source = 'datasets/yosemite_1536_no_crop/zone_A/labels'\n",
    "output_folder = 'datasets/yosemite_1536'\n",
    "zone = 'zone_A'\n",
    "split_9_images_labels(image_source, label_source, output_folder, zone, 3, 3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Adg9-npixstZ"
   },
   "source": [
    "# Create HDF5 for London and Yosemite dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ONHKIK1lzoHt"
   },
   "source": [
    "## Code for generate HDF5 for Yosemite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hOvFwrRzyARp"
   },
   "outputs": [],
   "source": [
    "# For Yosemite dataset\n",
    "TRAIN_PATH = ['datasets/yosemite_1536_np_crop/zone_B', 'datasets/yosemite_1536_no_crop/zone_D']\n",
    "TEST_PATH = ['datasets/yosemite_1536_no_crop/zone_A', 'datasets/yosemite_1536_no_crop/zone_C']\n",
    "DATASET_PATH = 'datasets/yosemite_1536/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wKQsq96FyCdX"
   },
   "outputs": [],
   "source": [
    "# Read Yosemite dataset files\n",
    "# Get the list of image files in the training and testing data\n",
    "TRAIN_IMAGES = []\n",
    "for path in TRAIN_PATH:\n",
    "    TRAIN_IMAGES += list([os.path.join(path, \"images\", file) for file in os.listdir(os.path.join(path, \"images\")) if file[-4:] == \".jpg\"])\n",
    "\n",
    "TEST_IMAGES = []\n",
    "for path in TEST_PATH:\n",
    "    TEST_IMAGES += list([os.path.join(path, \"images\", file) for file in os.listdir(os.path.join(path, \"images\")) if file[-4:] == \".jpg\"])\n",
    "\n",
    "TRAIN_SIZE = len(TRAIN_IMAGES)\n",
    "TEST_SIZE = len(TEST_IMAGES)\n",
    "\n",
    "X, Y, _ = plt.imread('datasets/yosemite_1536_no_crop/zone_A/images/IMG_0.jpg').shape\n",
    "print(X, Y)\n",
    "\n",
    "# Print the number of images in the training and testing data\n",
    "print((TRAIN_SIZE, TEST_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wm34TnjSzqSO"
   },
   "outputs": [],
   "source": [
    "def create_hdf5(dataset_path: str, dataset: str):\n",
    "    \"\"\"\n",
    "    Create empty training and validation HDF5 files with placeholders\n",
    "    for images and labels (density maps).\n",
    "\n",
    "    Note:\n",
    "    Datasets are saved in [dataset_name]/train.h5 and [dataset_name]/valid.h5.\n",
    "    Existing files will be overwritten.\n",
    "\n",
    "    Args:\n",
    "        dataset_name: used to create a folder for train.h5 and valid.h5\n",
    "\n",
    "    Returns:\n",
    "        A tuple of pointers to training and validation HDF5 files.\n",
    "    \"\"\"\n",
    "    # create output folder if it does not exist\n",
    "    os.makedirs(dataset_path, exist_ok=True)\n",
    "\n",
    "    # create HDF5 files: [dataset_name]/(train | valid).h5\n",
    "    train_h5 = h5py.File(os.path.join(dataset_path, f'train_{dataset}.h5'), 'w')\n",
    "    valid_h5 = h5py.File(os.path.join(dataset_path, f'valid_{dataset}.h5'), 'w')\n",
    "\n",
    "    return train_h5, valid_h5\n",
    "\n",
    "\n",
    "def generate_label(label_info: np.array, image_shape: List[int]):\n",
    "    \"\"\"\n",
    "    Generate a density map based on objects positions.\n",
    "\n",
    "    Args:\n",
    "        label_info: (x, y) objects positions\n",
    "        image_shape: (width, height) of a density map to be generated\n",
    "\n",
    "    Returns:\n",
    "        A density map.\n",
    "    \"\"\"\n",
    "    # create an empty density map\n",
    "    label = np.zeros(image_shape, dtype=np.float32)\n",
    "\n",
    "    # loop over objects positions and marked them with 100 on a label\n",
    "    # note: *_ because some datasets contain more info except x, y coordinates\n",
    "    for x, y in label_info:\n",
    "        if y < image_shape[0] and x < image_shape[1]:\n",
    "            label[int(y)][int(x)] = 1\n",
    "\n",
    "    # apply a convolution with a Gaussian kernel\n",
    "    # sigma = avg_box(label_info, image_shape[0])\n",
    "    # label = gaussian_filter(label, sigma = 10)\n",
    "    label = gaussian_filter_density(label)\n",
    "\n",
    "    return label\n",
    "\n",
    "\n",
    "def generate_our_own_data(dataset_name):\n",
    "    # create training and validation HDF5 files\n",
    "\n",
    "    # train.h5 and valid.h5 are created in dataloader\n",
    "    train_h5, valid_h5 = create_hdf5(\"dataloader/\", dataset_name)\n",
    "\n",
    "    def fill_h5(h5, label_path, train=True):\n",
    "        \"\"\"\n",
    "        Save images and labels in given HDF5 file.\n",
    "\n",
    "        Args:\n",
    "            h5: HDF5 file\n",
    "            label_path: path to label file\n",
    "        \"\"\"\n",
    "        # source directory of the image\n",
    "\n",
    "        labels = []\n",
    "\n",
    "        with open(label_path, \"r\") as f:\n",
    "            for tree in f.readlines():\n",
    "                x, y = tree.split(\" \")\n",
    "                labels.append((float(x), float(y)))\n",
    "\n",
    "        # generate a density map by applying a Gaussian filter\n",
    "        label = generate_label(labels, [Y, X])\n",
    "\n",
    "        # save data to HDF5 file\n",
    "        h5.create_dataset(os.path.basename(label_path).replace(\".txt\", \"\"), (1, 1, *(X, Y)))\n",
    "        h5[os.path.basename(label_path).replace(\".txt\", \"\")][0, 0] = label\n",
    "\n",
    "    # fill HDF5 files with data and labels from training and testing datasets\n",
    "    for i, img_path in enumerate(TRAIN_IMAGES):\n",
    "        print(\"train\", i)\n",
    "        fill_h5(train_h5, img_path.replace(\".jpg\", \".txt\").replace(\"images\", \"labels\"))\n",
    "    train_h5.close()\n",
    "\n",
    "    for i, img_path in enumerate(TEST_IMAGES):\n",
    "        print(\"test\", i)\n",
    "        fill_h5(valid_h5, img_path.replace(\".jpg\", \".txt\").replace(\"images\", \"labels\"), train=False)\n",
    "    # close HDF5 files\n",
    "    valid_h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7W-3kc4L3gnz"
   },
   "outputs": [],
   "source": [
    "generate_our_own_data(\"yosemite_1536_no_crop\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for split Yosemite density map o size 1536x1536 to 512x512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Split code\n",
    "import os\n",
    "import h5py\n",
    "import numpy as np\n",
    "\n",
    "def splitDensityMap(original_file_path: str):\n",
    "    \"\"\"\n",
    "    Split the density map into nine smaller sections and save them as separate datasets in a new HDF5 file.\n",
    "\n",
    "    Args:\n",
    "        original_file_path: The path to the original HDF5 file containing the density maps.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    # Open the original HDF5 file\n",
    "    with h5py.File(original_file_path, 'r') as f:\n",
    "        combined_sections = {}\n",
    "        print(len(f.keys()))\n",
    "        for key in f.keys():\n",
    "            data = f[key][:]\n",
    "\n",
    "            # Split the data into nine smaller sections\n",
    "            height, width = data.shape[2:4]\n",
    "            third_height = height // 3\n",
    "            third_width = width // 3\n",
    "\n",
    "            sections = []\n",
    "            for i in range(3):\n",
    "                for j in range(3):\n",
    "                    sections.append(data[:, :, i*third_height:(i+1)*third_height, j*third_width:(j+1)*third_width])\n",
    "\n",
    "            combined_sections[key] = sections\n",
    "\n",
    "        # Get the directory path of the original file\n",
    "        original_dir = os.path.dirname(original_file_path)\n",
    "\n",
    "        # Create a new HDF5 file to save the combined sections\n",
    "        # Change the file name\n",
    "        combined_file_name = os.path.basename(original_file_path).replace('.h5', '_sections.h5')\n",
    "        combined_file_path = os.path.join(original_dir, combined_file_name)\n",
    "        with h5py.File(combined_file_path, 'w') as combined_file:\n",
    "            for key, sections in combined_sections.items():\n",
    "                for i, section_data in enumerate(sections):\n",
    "                    # Create a dataset for each section in the new HDF5 file\n",
    "                    combined_file.create_dataset(f'{key}_section_{i}', data=section_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_file_path = 'dataloader/train_yosemite_1536.h5' # Specify the path to the original HDF5 file\n",
    "splitDensityMap(original_file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Code for generate HDF5 for London dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DslK4HFbx-jf"
   },
   "outputs": [],
   "source": [
    "# For London dataset\n",
    "# Define the paths to the training, validation and testing data\n",
    "TRAIN_PATH = 'datasets/london/train'\n",
    "VAL_PATH = 'datasets/london/val'\n",
    "TEST_PATH = 'datasets/london/test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FtYnQTQJypcY"
   },
   "outputs": [],
   "source": [
    "# Read London dataset files\n",
    "TRAIN_IMAGES = list([file for file in os.listdir(TRAIN_PATH + \"/images\") if file[-4:] == \".jpg\"])\n",
    "VAL_IMAGES = list([file for file in os.listdir(VAL_PATH + \"/images\") if file[-4:] == \".jpg\"])\n",
    "TRAIN_VAL_IMAGES = TRAIN_IMAGES + VAL_IMAGES\n",
    "\n",
    "TEST_IMAGES = list([file for file in os.listdir(TEST_PATH + \"/images\") if file[-4:] == \".jpg\"])\n",
    "\n",
    "# Get the number of images in the training, validation and testing data\n",
    "TRAIN_SIZE = len(TRAIN_IMAGES)\n",
    "VAL_SIZE = len(VAL_IMAGES)\n",
    "TRAIN_VAL_SIZE = TRAIN_SIZE + VAL_SIZE\n",
    "TEST_SIZE = len(TEST_IMAGES)\n",
    "\n",
    "# Get the dimensions of the images\n",
    "X, Y, _ = plt.imread(os.path.join(TRAIN_PATH, \"images\", TRAIN_IMAGES[0])).shape\n",
    "print(X, Y)\n",
    "\n",
    "print((TRAIN_VAL_SIZE, TEST_SIZE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_hdf5(dataset_path: str, dataset: str):\n",
    "    \"\"\"\n",
    "    Create empty training and validation HDF5 files with placeholders\n",
    "    for images and labels (density maps).\n",
    "\n",
    "    Note:\n",
    "    Datasets are saved in [dataset_name]/train.h5 and [dataset_name]/valid.h5.\n",
    "    Existing files will be overwritten.\n",
    "\n",
    "    Args:\n",
    "        dataset_name: used to create a folder for train.h5 and valid.h5\n",
    "\n",
    "    Returns:\n",
    "        A tuple of pointers to training and validation HDF5 files.\n",
    "    \"\"\"\n",
    "    # create output folder if it does not exist\n",
    "    os.makedirs(dataset_path, exist_ok=True)\n",
    "\n",
    "    # create HDF5 files: [dataset_name]/(train | valid).h5\n",
    "    train_h5 = h5py.File(os.path.join(dataset_path, f'train_{dataset}.h5'), 'w')\n",
    "    valid_h5 = h5py.File(os.path.join(dataset_path, f'valid_{dataset}.h5'), 'w')\n",
    "\n",
    "    return train_h5, valid_h5\n",
    "\n",
    "\n",
    "def generate_label(img_path, root_path):\n",
    "    \"\"\"\n",
    "    Generate a density map based on objects positions.\n",
    "\n",
    "    Args:\n",
    "        label_info: (x, y) objects positions\n",
    "        image_shape: (width, height) of a density map to be generated\n",
    "\n",
    "    Returns:\n",
    "        A density map.\n",
    "    \"\"\"\n",
    "    # create an empty density map\n",
    "    # Get the original label from the .mat file and convert it to a numpy array\n",
    "    name = os.path.basename(img_path).split('.')[0]\n",
    "    gd_path = os.path.join(root_path, 'labels', 'GT_{}.mat'.format(name))\n",
    "    gauss_path = os.path.join(root_path, 'labels', '{}_densitymap.npy'.format(name))\n",
    "    gauss_im = torch.from_numpy(np.load(gauss_path)).float()\n",
    "\n",
    "    return gauss_im, name\n",
    "\n",
    "\n",
    "def generate_our_own_data(dataset_name):\n",
    "    # create training and validation HDF5 files\n",
    "\n",
    "    # train.h5 and valid.h5 are created in /content\n",
    "    train_h5, valid_h5 = create_hdf5(\"dataloader/\", dataset_name)\n",
    "\n",
    "    def fill_h5(h5, file, root):\n",
    "        \"\"\"\n",
    "        Save images and labels in given HDF5 file.\n",
    "\n",
    "        Args:\n",
    "            h5: HDF5 file\n",
    "            file: filename\n",
    "        \"\"\"\n",
    "        # source directory of the image\n",
    "\n",
    "        # generate a density map by applying a Gaussian filter\n",
    "        label, name = generate_label(file, root)\n",
    "\n",
    "        # save data to HDF5 file\n",
    "        h5.create_dataset(name, (1, 1, *(X, Y)))\n",
    "        h5[name][0, 0] = label\n",
    "\n",
    "    # fill HDF5 files with data and labels from training and testing datasets\n",
    "    for i, file_name in enumerate(TRAIN_VAL_IMAGES):\n",
    "        print(\"train\", i)\n",
    "        if i < TRAIN_SIZE:\n",
    "            path = TRAIN_PATH\n",
    "        else:\n",
    "            path = VAL_PATH\n",
    "        fill_h5(train_h5, os.path.join(path, \"images\", file_name), path)\n",
    "\n",
    "    for i, file_name in enumerate(TEST_IMAGES):\n",
    "        print(\"test\", i)\n",
    "        fill_h5(valid_h5, os.path.join(path, \"images\", file_name), TEST_PATH)\n",
    "    # close HDF5 files\n",
    "    train_h5.close()\n",
    "    valid_h5.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_our_own_data(\"london\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "hn7QIEm6rhzb"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
