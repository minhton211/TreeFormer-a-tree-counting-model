{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Import requirements files"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {},
      "outputs": [],
      "source": [
        "from PIL import Image\n",
        "import PIL.Image\n",
        "import os\n",
        "import random\n",
        "import matplotlib.pyplot as plt\n",
        "import shutil\n",
        "import zipfile\n",
        "from glob import glob\n",
        "from typing import List, Tuple\n",
        "\n",
        "import click\n",
        "import h5py\n",
        "import numpy as np\n",
        "from scipy.io import loadmat\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "from utils import avg_box, gaussian_filter_density\n",
        "import math\n",
        "import torch\n",
        "import scipy.io as sio\n",
        "\n",
        "PIL.Image.MAX_IMAGE_PIXELS = 1262080000"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hn7QIEm6rhzb"
      },
      "source": [
        "# Cropping Yosemite dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EfU80poFrkd5"
      },
      "source": [
        "**Create annotation for Yosemite dataset**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "xyjdvD7CrqXC"
      },
      "outputs": [],
      "source": [
        "file_path = \"Dataset/Yosemite/labels.txt\"\n",
        "im = Image.open('Dataset/Yosemite/z20_label.png') # Can be many different formats.\n",
        "pix = im.load()\n",
        "x, y = im.size\n",
        "with open(file_path, \"w\") as f:\n",
        "  for i in range(x):\n",
        "    for j in range(y):\n",
        "      value = pix[i, j]\n",
        "      if value > 0:\n",
        "        rel_x = i\n",
        "        rel_y = j\n",
        "        f.write(f\"{rel_x} {rel_y}\\n\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xmzqh9dltGv2"
      },
      "source": [
        "## Crop function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "1RboNxQctLs1"
      },
      "outputs": [],
      "source": [
        "def smallCrop(image, cw, ch, labels, left, top):\n",
        "    width, height = image.size\n",
        "    if cw >= min(width, height):\n",
        "        raise ValueError(\"Crop size exceeds image dimensions\")\n",
        "\n",
        "    # 27200 x 46400 pixels in image\n",
        "    # zone 19200 x 38400\n",
        "    while True:\n",
        "        #Define the zone to crop\n",
        "        right = left + cw\n",
        "        bottom = top + ch\n",
        "        cropped_image = image.crop((left, top, right, bottom))\n",
        "\n",
        "        updated_labels = []\n",
        "        for x, y in labels:\n",
        "            if left <= x <= right and top <= y  <= bottom:\n",
        "                # Label is inside the cropped area, update its coordinates\n",
        "                updated_x = (x - left)\n",
        "                updated_y = (y - top)\n",
        "                updated_labels.append((updated_x, updated_y))\n",
        "\n",
        "        return cropped_image, updated_labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "WtnRCZAgtdYg"
      },
      "outputs": [],
      "source": [
        "def main_row(input_image_path, input_label_path, output_folder, cw, ch):\n",
        "    # Create output folders if they don't exist\n",
        "    os.makedirs(output_folder, exist_ok=True)\n",
        "\n",
        "    folders = ['zone_A', 'zone_B', 'zone_C', 'zone_D']\n",
        "\n",
        "    for folder in folders:\n",
        "      zone = os.path.join(output_folder, folder)\n",
        "      os.makedirs(os.path.join(zone, 'images'), exist_ok=True)\n",
        "      os.makedirs(os.path.join(zone, 'labels'), exist_ok=True)\n",
        "\n",
        "    # Load the input image\n",
        "    image = Image.open(input_image_path)\n",
        "\n",
        "    # Load labels from a txt file (assuming one label per line in the format \"x y\")\n",
        "    with open(input_label_path, 'r') as label_file:\n",
        "        labels = [tuple(map(float, line.strip().split())) for line in label_file]\n",
        "\n",
        "    x_min = 4000\n",
        "    x_max = x_min + int(19200/4) - cw\n",
        "    y_min = 4000\n",
        "    y_max = y_min + 38400\n",
        "    count = 0\n",
        "\n",
        "    for i in range(len(folders)):\n",
        "      print(f\"Width range {x_min} - {x_max}\")\n",
        "      print(f\"Height range {y_min} - {y_max}\")\n",
        "      j = 1\n",
        "\n",
        "      for top in range(y_min, y_max, ch):\n",
        "        for left in range(x_min, x_max, cw):\n",
        "          print(count, end = \" \")\n",
        "          print(\"Left:\", left, \"Top:\", top)\n",
        "          cropped_image, updated_labels = smallCrop(image, cw, ch, labels, left, top)\n",
        "\n",
        "          # Save the cropped image\n",
        "          output_image_path = os.path.join(output_folder, folders[i], 'images', f'IMG_{count}.jpg')\n",
        "          cropped_image.save(output_image_path)\n",
        "\n",
        "          # Save the updated labels to a new txt file\n",
        "          output_label_path = os.path.join(output_folder, folders[i], 'labels', f'IMG_{count}.txt')\n",
        "          with open(output_label_path, 'w') as updated_label_file:\n",
        "              for x, y in updated_labels:\n",
        "                  updated_label_file.write(f\"{x} {y}\\n\")\n",
        "          j += 1\n",
        "          count += 1\n",
        "      print(f\"The number of images and labels in {folders[i]}: {j-1}\\n\")\n",
        "      x_min += int(19200/4)\n",
        "      x_max += int(19200/4)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "H5CZ6o0MthHk"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Width range 4000 - 7264\n",
            "Height range 4000 - 42400\n",
            "0 Left: 4000 Top: 4000\n",
            "1 Left: 5536 Top: 4000\n",
            "2 Left: 7072 Top: 4000\n",
            "3 Left: 4000 Top: 6560\n",
            "4 Left: 5536 Top: 6560\n",
            "5 Left: 7072 Top: 6560\n",
            "6 Left: 4000 Top: 9120\n",
            "7 Left: 5536 Top: 9120\n",
            "8 Left: 7072 Top: 9120\n",
            "9 Left: 4000 Top: 11680\n",
            "10 Left: 5536 Top: 11680\n",
            "11 Left: 7072 Top: 11680\n",
            "12 Left: 4000 Top: 14240\n",
            "13 Left: 5536 Top: 14240\n",
            "14 Left: 7072 Top: 14240\n",
            "15 Left: 4000 Top: 16800\n",
            "16 Left: 5536 Top: 16800\n",
            "17 Left: 7072 Top: 16800\n",
            "18 Left: 4000 Top: 19360\n",
            "19 Left: 5536 Top: 19360\n",
            "20 Left: 7072 Top: 19360\n",
            "21 Left: 4000 Top: 21920\n",
            "22 Left: 5536 Top: 21920\n",
            "23 Left: 7072 Top: 21920\n",
            "24 Left: 4000 Top: 24480\n",
            "25 Left: 5536 Top: 24480\n",
            "26 Left: 7072 Top: 24480\n",
            "27 Left: 4000 Top: 27040\n",
            "28 Left: 5536 Top: 27040\n",
            "29 Left: 7072 Top: 27040\n",
            "30 Left: 4000 Top: 29600\n",
            "31 Left: 5536 Top: 29600\n",
            "32 Left: 7072 Top: 29600\n",
            "33 Left: 4000 Top: 32160\n",
            "34 Left: 5536 Top: 32160\n",
            "35 Left: 7072 Top: 32160\n",
            "36 Left: 4000 Top: 34720\n",
            "37 Left: 5536 Top: 34720\n",
            "38 Left: 7072 Top: 34720\n",
            "39 Left: 4000 Top: 37280\n",
            "40 Left: 5536 Top: 37280\n",
            "41 Left: 7072 Top: 37280\n",
            "42 Left: 4000 Top: 39840\n",
            "43 Left: 5536 Top: 39840\n",
            "44 Left: 7072 Top: 39840\n",
            "The number of images and labels in zone_A: 45\n",
            "\n",
            "Width range 8800 - 12064\n",
            "Height range 4000 - 42400\n",
            "45 Left: 8800 Top: 4000\n",
            "46 Left: 10336 Top: 4000\n",
            "47 Left: 11872 Top: 4000\n",
            "48 Left: 8800 Top: 6560\n",
            "49 Left: 10336 Top: 6560\n",
            "50 Left: 11872 Top: 6560\n",
            "51 Left: 8800 Top: 9120\n",
            "52 Left: 10336 Top: 9120\n",
            "53 Left: 11872 Top: 9120\n",
            "54 Left: 8800 Top: 11680\n",
            "55 Left: 10336 Top: 11680\n",
            "56 Left: 11872 Top: 11680\n",
            "57 Left: 8800 Top: 14240\n",
            "58 Left: 10336 Top: 14240\n",
            "59 Left: 11872 Top: 14240\n",
            "60 Left: 8800 Top: 16800\n",
            "61 Left: 10336 Top: 16800\n",
            "62 Left: 11872 Top: 16800\n",
            "63 Left: 8800 Top: 19360\n",
            "64 Left: 10336 Top: 19360\n",
            "65 Left: 11872 Top: 19360\n",
            "66 Left: 8800 Top: 21920\n",
            "67 Left: 10336 Top: 21920\n",
            "68 Left: 11872 Top: 21920\n",
            "69 Left: 8800 Top: 24480\n",
            "70 Left: 10336 Top: 24480\n",
            "71 Left: 11872 Top: 24480\n",
            "72 Left: 8800 Top: 27040\n",
            "73 Left: 10336 Top: 27040\n",
            "74 Left: 11872 Top: 27040\n",
            "75 Left: 8800 Top: 29600\n",
            "76 Left: 10336 Top: 29600\n",
            "77 Left: 11872 Top: 29600\n",
            "78 Left: 8800 Top: 32160\n",
            "79 Left: 10336 Top: 32160\n",
            "80 Left: 11872 Top: 32160\n",
            "81 Left: 8800 Top: 34720\n",
            "82 Left: 10336 Top: 34720\n",
            "83 Left: 11872 Top: 34720\n",
            "84 Left: 8800 Top: 37280\n",
            "85 Left: 10336 Top: 37280\n",
            "86 Left: 11872 Top: 37280\n",
            "87 Left: 8800 Top: 39840\n",
            "88 Left: 10336 Top: 39840\n",
            "89 Left: 11872 Top: 39840\n",
            "The number of images and labels in zone_B: 45\n",
            "\n",
            "Width range 13600 - 16864\n",
            "Height range 4000 - 42400\n",
            "90 Left: 13600 Top: 4000\n",
            "91 Left: 15136 Top: 4000\n",
            "92 Left: 16672 Top: 4000\n",
            "93 Left: 13600 Top: 6560\n",
            "94 Left: 15136 Top: 6560\n",
            "95 Left: 16672 Top: 6560\n",
            "96 Left: 13600 Top: 9120\n",
            "97 Left: 15136 Top: 9120\n",
            "98 Left: 16672 Top: 9120\n",
            "99 Left: 13600 Top: 11680\n",
            "100 Left: 15136 Top: 11680\n",
            "101 Left: 16672 Top: 11680\n",
            "102 Left: 13600 Top: 14240\n",
            "103 Left: 15136 Top: 14240\n",
            "104 Left: 16672 Top: 14240\n",
            "105 Left: 13600 Top: 16800\n",
            "106 Left: 15136 Top: 16800\n",
            "107 Left: 16672 Top: 16800\n",
            "108 Left: 13600 Top: 19360\n",
            "109 Left: 15136 Top: 19360\n",
            "110 Left: 16672 Top: 19360\n",
            "111 Left: 13600 Top: 21920\n",
            "112 Left: 15136 Top: 21920\n",
            "113 Left: 16672 Top: 21920\n",
            "114 Left: 13600 Top: 24480\n",
            "115 Left: 15136 Top: 24480\n",
            "116 Left: 16672 Top: 24480\n",
            "117 Left: 13600 Top: 27040\n",
            "118 Left: 15136 Top: 27040\n",
            "119 Left: 16672 Top: 27040\n",
            "120 Left: 13600 Top: 29600\n",
            "121 Left: 15136 Top: 29600\n",
            "122 Left: 16672 Top: 29600\n",
            "123 Left: 13600 Top: 32160\n",
            "124 Left: 15136 Top: 32160\n",
            "125 Left: 16672 Top: 32160\n",
            "126 Left: 13600 Top: 34720\n",
            "127 Left: 15136 Top: 34720\n",
            "128 Left: 16672 Top: 34720\n",
            "129 Left: 13600 Top: 37280\n",
            "130 Left: 15136 Top: 37280\n",
            "131 Left: 16672 Top: 37280\n",
            "132 Left: 13600 Top: 39840\n",
            "133 Left: 15136 Top: 39840\n",
            "134 Left: 16672 Top: 39840\n",
            "The number of images and labels in zone_C: 45\n",
            "\n",
            "Width range 18400 - 21664\n",
            "Height range 4000 - 42400\n",
            "135 Left: 18400 Top: 4000\n",
            "136 Left: 19936 Top: 4000\n",
            "137 Left: 21472 Top: 4000\n",
            "138 Left: 18400 Top: 6560\n",
            "139 Left: 19936 Top: 6560\n",
            "140 Left: 21472 Top: 6560\n",
            "141 Left: 18400 Top: 9120\n",
            "142 Left: 19936 Top: 9120\n",
            "143 Left: 21472 Top: 9120\n",
            "144 Left: 18400 Top: 11680\n",
            "145 Left: 19936 Top: 11680\n",
            "146 Left: 21472 Top: 11680\n",
            "147 Left: 18400 Top: 14240\n",
            "148 Left: 19936 Top: 14240\n",
            "149 Left: 21472 Top: 14240\n",
            "150 Left: 18400 Top: 16800\n",
            "151 Left: 19936 Top: 16800\n",
            "152 Left: 21472 Top: 16800\n",
            "153 Left: 18400 Top: 19360\n",
            "154 Left: 19936 Top: 19360\n",
            "155 Left: 21472 Top: 19360\n",
            "156 Left: 18400 Top: 21920\n",
            "157 Left: 19936 Top: 21920\n",
            "158 Left: 21472 Top: 21920\n",
            "159 Left: 18400 Top: 24480\n",
            "160 Left: 19936 Top: 24480\n",
            "161 Left: 21472 Top: 24480\n",
            "162 Left: 18400 Top: 27040\n",
            "163 Left: 19936 Top: 27040\n",
            "164 Left: 21472 Top: 27040\n",
            "165 Left: 18400 Top: 29600\n",
            "166 Left: 19936 Top: 29600\n",
            "167 Left: 21472 Top: 29600\n",
            "168 Left: 18400 Top: 32160\n",
            "169 Left: 19936 Top: 32160\n",
            "170 Left: 21472 Top: 32160\n",
            "171 Left: 18400 Top: 34720\n",
            "172 Left: 19936 Top: 34720\n",
            "173 Left: 21472 Top: 34720\n",
            "174 Left: 18400 Top: 37280\n",
            "175 Left: 19936 Top: 37280\n",
            "176 Left: 21472 Top: 37280\n",
            "177 Left: 18400 Top: 39840\n",
            "178 Left: 19936 Top: 39840\n",
            "179 Left: 21472 Top: 39840\n",
            "The number of images and labels in zone_D: 45\n",
            "\n"
          ]
        }
      ],
      "source": [
        "#Row by Row cropping\n",
        "input_image_path = 'Dataset/Yosemite/z20_data.png'  # Specify the path to your input image\n",
        "input_label_path = 'Dataset/Yosemite/labels.txt'  # Specify the path to your input labels file\n",
        "output_folder = 'Dataset/Yosemite/Dataset_Row_1536x2560'  # Specify the output folder where cropped images and labels will be saved\n",
        "crop_width =  1536 # Specify the size of the square crop (both width and height)\n",
        "crop_height = 2560\n",
        "\n",
        "main_row(input_image_path, input_label_path, output_folder, crop_width, crop_height)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MDw54ybouo3M"
      },
      "outputs": [],
      "source": [
        "def plot_cropped_images_with_labels(folder):\n",
        "\n",
        "    image_folder = os.path.join(folder,'images')\n",
        "    label_folder = os.path.join(folder,'labels')\n",
        "    # List image and label files in the respective folders\n",
        "    image_files = os.listdir(image_folder)\n",
        "    label_files = os.listdir(label_folder)\n",
        "\n",
        "    for image_filename in image_files:\n",
        "        # Check if a corresponding label file exists\n",
        "        label_filename = os.path.splitext(image_filename)[0] + '.txt'\n",
        "        if label_filename not in label_files:\n",
        "            continue\n",
        "\n",
        "        image_path = os.path.join(image_folder, image_filename)\n",
        "        label_path = os.path.join(label_folder, label_filename)\n",
        "\n",
        "        # Load the cropped image\n",
        "        cropped_image = Image.open(image_path)\n",
        "\n",
        "        # Load labels from the provided label file\n",
        "        with open(label_path, 'r') as label_file:\n",
        "            labels = [tuple(map(float, line.strip().split())) for line in label_file]\n",
        "\n",
        "        plt.figure(figsize=(6, 6))\n",
        "        plt.imshow(cropped_image)\n",
        "        plt.title(image_filename)\n",
        "\n",
        "        for x, y in labels:\n",
        "            plt.plot(x, y, 'ro', markersize=2)  # Plot labels as red points\n",
        "\n",
        "        plt.axis('off')\n",
        "        plt.show()\n",
        "\n",
        "folder = 'Dataset/Yosemite/Dataset_Row_1536x2560/zone_A'\n",
        "plot_cropped_images_with_labels(folder)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Adg9-npixstZ"
      },
      "source": [
        "# Create HDF5 for London and Yosemite dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ONHKIK1lzoHt"
      },
      "source": [
        "## Code for generate HDF5 for Yosemite"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "id": "hOvFwrRzyARp"
      },
      "outputs": [],
      "source": [
        "# For Yosemite dataset\n",
        "TRAIN_PATH = ['Dataset/Yosemite/Dataset_Row_1536x2560/zone_B', 'Dataset/Yosemite/Dataset_Row_1536x2560/zone_D']\n",
        "TEST_PATH = ['Dataset/Yosemite/Dataset_Row_1536x2560/zone_A', 'Dataset/Yosemite/Dataset_Row_1536x2560/zone_C']\n",
        "DATASET_PATH = 'Dataset/Yosemite/Dataset_Row_1536x2560'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wKQsq96FyCdX"
      },
      "outputs": [],
      "source": [
        "# Read Yosemite dataset files\n",
        "TRAIN_IMAGES = []\n",
        "for path in TRAIN_PATH:\n",
        "    TRAIN_IMAGES += list([os.path.join(path, \"images\", file) for file in os.listdir(os.path.join(path, \"images\")) if file[-4:] == \".jpg\"])\n",
        "\n",
        "TEST_IMAGES = []\n",
        "for path in TEST_PATH:\n",
        "    TEST_IMAGES += list([os.path.join(path, \"images\", file) for file in os.listdir(os.path.join(path, \"images\")) if file[-4:] == \".jpg\"])\n",
        "\n",
        "TRAIN_SIZE = len(TRAIN_IMAGES)\n",
        "TEST_SIZE = len(TEST_IMAGES)\n",
        "\n",
        "X, Y, _ = plt.imread('Dataset/Yosemite/Dataset_Row_1536x2560/zone_A/images/IMG_0.jpg').shape\n",
        "print(X, Y)\n",
        "\n",
        "print((TRAIN_SIZE, TEST_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "wm34TnjSzqSO"
      },
      "outputs": [],
      "source": [
        "def create_hdf5(dataset_path: str, dataset: str):\n",
        "    \"\"\"\n",
        "    Create empty training and validation HDF5 files with placeholders\n",
        "    for images and labels (density maps).\n",
        "\n",
        "    Note:\n",
        "    Datasets are saved in [dataset_name]/train.h5 and [dataset_name]/valid.h5.\n",
        "    Existing files will be overwritten.\n",
        "\n",
        "    Args:\n",
        "        dataset_name: used to create a folder for train.h5 and valid.h5\n",
        "\n",
        "    Returns:\n",
        "        A tuple of pointers to training and validation HDF5 files.\n",
        "    \"\"\"\n",
        "    # create output folder if it does not exist\n",
        "    os.makedirs(dataset_path, exist_ok=True)\n",
        "\n",
        "    # create HDF5 files: [dataset_name]/(train | valid).h5\n",
        "    train_h5 = h5py.File(os.path.join(dataset_path, f'train_{dataset}.h5'), 'w')\n",
        "    valid_h5 = h5py.File(os.path.join(dataset_path, f'valid_{dataset}.h5'), 'w')\n",
        "\n",
        "    return train_h5, valid_h5\n",
        "\n",
        "\n",
        "def generate_label(label_info: np.array, image_shape: List[int]):\n",
        "    \"\"\"\n",
        "    Generate a density map based on objects positions.\n",
        "\n",
        "    Args:\n",
        "        label_info: (x, y) objects positions\n",
        "        image_shape: (width, height) of a density map to be generated\n",
        "\n",
        "    Returns:\n",
        "        A density map.\n",
        "    \"\"\"\n",
        "    # create an empty density map\n",
        "    label = np.zeros(image_shape, dtype=np.float32)\n",
        "\n",
        "    # loop over objects positions and marked them with 100 on a label\n",
        "    # note: *_ because some datasets contain more info except x, y coordinates\n",
        "    for x, y in label_info:\n",
        "        if y < image_shape[0] and x < image_shape[1]:\n",
        "            label[int(y)][int(x)] = 1\n",
        "\n",
        "    # apply a convolution with a Gaussian kernel\n",
        "    # sigma = avg_box(label_info, image_shape[0])\n",
        "    # label = gaussian_filter(label, sigma = 10)\n",
        "    label = gaussian_filter_density(label)\n",
        "\n",
        "    return label\n",
        "\n",
        "\n",
        "def generate_our_own_data(dataset_name):\n",
        "    # create training and validation HDF5 files\n",
        "\n",
        "    # train.h5 and valid.h5 are created in /content\n",
        "    train_h5, valid_h5 = create_hdf5(\"Density_Map/\", dataset_name)\n",
        "\n",
        "    def fill_h5(h5, label_path, train=True):\n",
        "        \"\"\"\n",
        "        Save images and labels in given HDF5 file.\n",
        "\n",
        "        Args:\n",
        "            h5: HDF5 file\n",
        "            label_path: path to label file\n",
        "        \"\"\"\n",
        "        # source directory of the image\n",
        "\n",
        "        labels = []\n",
        "\n",
        "        with open(label_path, \"r\") as f:\n",
        "            for tree in f.readlines():\n",
        "                x, y = tree.split(\" \")\n",
        "                labels.append((float(x), float(y)))\n",
        "\n",
        "        # generate a density map by applying a Gaussian filter\n",
        "        label = generate_label(labels, [Y, X])\n",
        "\n",
        "        # save data to HDF5 file\n",
        "        h5.create_dataset(os.path.basename(label_path).replace(\".txt\", \"\"), (1, 1, *(X, Y)))\n",
        "        h5[os.path.basename(label_path).replace(\".txt\", \"\")][0, 0] = label\n",
        "\n",
        "    for i, img_path in enumerate(TRAIN_IMAGES):\n",
        "        print(\"train\", i)\n",
        "        fill_h5(train_h5, img_path.replace(\".jpg\", \".txt\").replace(\"images\", \"labels\"))\n",
        "    train_h5.close()\n",
        "\n",
        "    for i, img_path in enumerate(TEST_IMAGES):\n",
        "        print(\"test\", i)\n",
        "        fill_h5(valid_h5, img_path.replace(\".jpg\", \".txt\").replace(\"images\", \"labels\"), train=False)\n",
        "    # close HDF5 files\n",
        "    valid_h5.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7W-3kc4L3gnz"
      },
      "outputs": [],
      "source": [
        "generate_our_own_data(\"yosemite_1536x2560\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Code for generate HDF5 for London dataset"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "DslK4HFbx-jf"
      },
      "outputs": [],
      "source": [
        "# For London dataset\n",
        "TRAIN_PATH = 'Dataset/London/train'\n",
        "VAL_PATH = 'Dataset/London/val'\n",
        "TEST_PATH = 'Dataset/London/test'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FtYnQTQJypcY"
      },
      "outputs": [],
      "source": [
        "# Read London dataset files\n",
        "TRAIN_IMAGES = list([file for file in os.listdir(TRAIN_PATH + \"/images\") if file[-4:] == \".jpg\"])\n",
        "VAL_IMAGES = list([file for file in os.listdir(VAL_PATH + \"/images\") if file[-4:] == \".jpg\"])\n",
        "TRAIN_VAL_IMAGES = TRAIN_IMAGES + VAL_IMAGES\n",
        "TEST_IMAGES = list([file for file in os.listdir(TEST_PATH + \"/images\") if file[-4:] == \".jpg\"])\n",
        "\n",
        "TRAIN_SIZE = len(TRAIN_IMAGES)\n",
        "VAL_SIZE = len(VAL_IMAGES)\n",
        "TRAIN_VAL_SIZE = TRAIN_SIZE + VAL_SIZE\n",
        "TEST_SIZE = len(TEST_IMAGES)\n",
        "\n",
        "X, Y, _ = plt.imread(os.path.join(TRAIN_PATH, \"images\", TRAIN_IMAGES[0])).shape\n",
        "print(X, Y)\n",
        "\n",
        "print((TRAIN_VAL_SIZE, TEST_SIZE))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 38,
      "metadata": {},
      "outputs": [],
      "source": [
        "def create_hdf5(dataset_path: str, dataset: str):\n",
        "    \"\"\"\n",
        "    Create empty training and validation HDF5 files with placeholders\n",
        "    for images and labels (density maps).\n",
        "\n",
        "    Note:\n",
        "    Datasets are saved in [dataset_name]/train.h5 and [dataset_name]/valid.h5.\n",
        "    Existing files will be overwritten.\n",
        "\n",
        "    Args:\n",
        "        dataset_name: used to create a folder for train.h5 and valid.h5\n",
        "\n",
        "    Returns:\n",
        "        A tuple of pointers to training and validation HDF5 files.\n",
        "    \"\"\"\n",
        "    # create output folder if it does not exist\n",
        "    os.makedirs(dataset_path, exist_ok=True)\n",
        "\n",
        "    # create HDF5 files: [dataset_name]/(train | valid).h5\n",
        "    train_h5 = h5py.File(os.path.join(dataset_path, f'train_{dataset}.h5'), 'w')\n",
        "    valid_h5 = h5py.File(os.path.join(dataset_path, f'valid_{dataset}.h5'), 'w')\n",
        "\n",
        "    return train_h5, valid_h5\n",
        "\n",
        "\n",
        "def generate_label(img_path, root_path):\n",
        "    \"\"\"\n",
        "    Generate a density map based on objects positions.\n",
        "\n",
        "    Args:\n",
        "        label_info: (x, y) objects positions\n",
        "        image_shape: (width, height) of a density map to be generated\n",
        "\n",
        "    Returns:\n",
        "        A density map.\n",
        "    \"\"\"\n",
        "    # create an empty density map\n",
        "    name = os.path.basename(img_path).split('.')[0]\n",
        "    gd_path = os.path.join(root_path, 'labels', 'GT_{}.mat'.format(name))\n",
        "    gauss_path = os.path.join(root_path, 'labels', '{}_densitymap.npy'.format(name))\n",
        "    gauss_im = torch.from_numpy(np.load(gauss_path)).float()\n",
        "\n",
        "    return gauss_im, name\n",
        "\n",
        "\n",
        "def generate_our_own_data(dataset_name):\n",
        "    # create training and validation HDF5 files\n",
        "\n",
        "    # train.h5 and valid.h5 are created in /content\n",
        "    train_h5, valid_h5 = create_hdf5(\"Density_Map/\", dataset_name)\n",
        "\n",
        "    def fill_h5(h5, file, root):\n",
        "        \"\"\"\n",
        "        Save images and labels in given HDF5 file.\n",
        "\n",
        "        Args:\n",
        "            h5: HDF5 file\n",
        "            file: filename\n",
        "        \"\"\"\n",
        "        # source directory of the image\n",
        "\n",
        "        # generate a density map by applying a Gaussian filter\n",
        "        label, name = generate_label(file, root)\n",
        "\n",
        "        # save data to HDF5 file\n",
        "        h5.create_dataset(name, (1, 1, *(X, Y)))\n",
        "        h5[name][0, 0] = label\n",
        "\n",
        "    for i, file_name in enumerate(TRAIN_VAL_IMAGES):\n",
        "        print(\"train\", i)\n",
        "        if i < TRAIN_SIZE:\n",
        "            path = TRAIN_PATH\n",
        "        else:\n",
        "            path = VAL_PATH\n",
        "        fill_h5(train_h5, os.path.join(path, \"images\", file_name), path)\n",
        "\n",
        "    for i, file_name in enumerate(TEST_IMAGES):\n",
        "        print(\"test\", i)\n",
        "        fill_h5(valid_h5, os.path.join(path, \"images\", file_name), TEST_PATH)\n",
        "    # close HDF5 files\n",
        "    train_h5.close()\n",
        "    valid_h5.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "generate_our_own_data(\"london\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "hn7QIEm6rhzb"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
